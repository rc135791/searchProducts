{"ast":null,"code":"\"use strict\";\n/**\n * (C) Copyright IBM Corp. 2014, 2019.\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *      http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License\n */\n\nvar __extends = this && this.__extends || function () {\n  var _extendStatics = function extendStatics(d, b) {\n    _extendStatics = Object.setPrototypeOf || {\n      __proto__: []\n    } instanceof Array && function (d, b) {\n      d.__proto__ = b;\n    } || function (d, b) {\n      for (var p in b) {\n        if (b.hasOwnProperty(p)) d[p] = b[p];\n      }\n    };\n\n    return _extendStatics(d, b);\n  };\n\n  return function (d, b) {\n    _extendStatics(d, b);\n\n    function __() {\n      this.constructor = d;\n    }\n\n    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n  };\n}();\n\nvar ibm_cloud_sdk_core_1 = require(\"ibm-cloud-sdk-core\");\n\nvar stream_1 = require(\"stream\");\n\nvar websocket_1 = require(\"websocket\");\n\nvar websocket_utils_1 = require(\"./websocket-utils\");\n/**\n * pipe()-able Node.js Readable/Writeable stream - accepts binary audio and emits text in its `data` events.\n * Also emits `results` events with interim results and other data.\n *\n * Cannot be instantiated directly, instead created by calling #recognizeUsingWebSocket()\n *\n * Uses WebSockets under the hood. For audio with no recognizable speech, no `data` events are emitted.\n * @param {Object} options\n * @constructor\n */\n\n\nvar RecognizeStream =\n/** @class */\nfunction (_super) {\n  __extends(RecognizeStream, _super);\n  /**\n   * pipe()-able Node.js Duplex stream - accepts binary audio and emits text/objects in it's `data` events.\n   *\n   * Uses WebSockets under the hood. For audio with no recognizable speech, no `data` events are emitted.\n   *\n   * By default, only finalized text is emitted in the data events, however when `objectMode`/`readableObjectMode` and `interim_results` are enabled, both interim and final results objects are emitted.\n   * WriteableElementStream uses this, for example, to live-update the DOM with word-by-word transcriptions.\n   *\n   * Note that the WebSocket connection is not established until the first chunk of data is recieved. This allows for auto-detection of content type (for wav/flac/opus audio).\n   *\n   * @param {Options} options\n   * @param {Authenticator} options.authenticator - Authenticator to add Authorization header\n   * @param {string} [options.url] - Base url for service (default='wss://stream.watsonplatform.net/speech-to-text/api')\n   * @param {OutgoingHttpHeaders} [options.headers] - Only works in Node.js, not in browsers. Allows for custom headers to be set, including an Authorization header (preventing the need for auth tokens)\n   * @param {boolean} [options.readableObjectMode] - Emit `result` objects instead of string Buffers for the `data` events. Does not affect input (which must be binary)\n   * @param {boolean} [options.objectMode] - Alias for readableObjectMode\n   * @param {boolean} [options.disableSslVerification] - If true, disable SSL verification for the WebSocket connection (default=false)\n   * @param {Agent} [options.agent] - custom http(s) agent, useful for using the sdk behind a proxy (Node only)\n   * @param {string} [options.accessToken] - Bearer token to put in query string\n   * @param {string} [options.watsonToken] - Valid Watson authentication token (for Cloud Foundry)\n   * @param {string} [options.model] - The identifier of the model that is to be used for all recognition requests sent over the connection\n   * @param {string} [options.languageCustomizationId] - The customization ID (GUID) of a custom language model that is to be used for all requests sent over the connection\n   * @param {string} [options.acousticCustomizationId] - The customization ID (GUID) of a custom acoustic model that is to be used for the request\n   * @param {string} [options.baseModelVersion] - The version of the specified base model that is to be used for all requests sent over the connection\n   * @param {boolean} [options.xWatsonLearningOptOut] - Indicates whether IBM can use data that is sent over the connection to improve the service for future users (default=false)\n   * @param {string} [options.xWatsonMetadata] - Associates a customer ID with all data that is passed over the connection. The parameter accepts the argument customer_id={id}, where {id} is a random or generic string that is to be associated with the data\n   * @param {string} [options.contentType] - The format (MIME type) of the audio\n   * @param {number} [options.customizationWeight] - Tell the service how much weight to give to words from the custom language model compared to those from the base model for the current request\n   * @param {number} [options.inactivityTimeout] - The time in seconds after which, if only silence (no speech) is detected in the audio, the connection is closed (default=30)\n   * @param {boolean} [options.interimResults] - If true, the service returns interim results as a stream of JSON SpeechRecognitionResults objects (default=false)\n   * @param {string[]} [options.keywords] - An array of keyword strings to spot in the audio\n   * @param {number} [options.keywordsThreshold] - A confidence value that is the lower bound for spotting a keyword\n   * @param {number} [options.maxAlternatives] - The maximum number of alternative transcripts that the service is to return (default=1)\n   * @param {number} [options.wordAlternativesThreshold] - A confidence value that is the lower bound for identifying a hypothesis as a possible word alternative\n   * @param {boolean} [options.wordConfidence] - If true, the service returns a confidence measure in the range of 0.0 to 1.0 for each word (default=false)\n   * @param {boolean} [options.timestamps] - If true, the service returns time alignment for each word (default=false)\n   * @param {boolean} [options.profanityFilter] - If true, the service filters profanity from all output except for keyword results by replacing inappropriate words with a series of asterisks (default=true)\n   * @param {boolean} [options.smartFormatting] - If true, the service converts dates, times, series of digits and numbers, phone numbers, currency values, and internet addresses into more readable, conventional representations (default=false)\n   * @param {boolean} [options.speakerLabels] - If true, the response includes labels that identify which words were spoken by which participants in a multi-person exchange (default=false)\n   * @param {string} [options.grammarName] - The name of a grammar that is to be used with the recognition request\n   * @param {boolean} [options.redaction] - If true, the service redacts, or masks, numeric data from final transcripts (default=false)\n   * @param {boolean} [options.processingMetrics] - If true, requests processing metrics about the service's transcription of the input audio (default=false)\n   * @param {number} [options.processingMetricsInterval] - Specifies the interval in seconds at which the service is to return processing metrics\n   * @param {boolean} [options.audioMetrics] - If true, requests detailed information about the signal characteristics of the input audio (detailed=false)\n   * @constructor\n   */\n\n\n  function RecognizeStream(options) {\n    var _this = this; // this stream only supports objectMode on the output side.\n    // It must receive binary data input.\n\n\n    if (options.objectMode) {\n      options.readableObjectMode = true;\n      delete options.objectMode;\n    }\n\n    _this = _super.call(this, options) || this;\n\n    if (_this.readableObjectMode === undefined) {\n      _this.readableObjectMode = options.readableObjectMode === true;\n    }\n\n    _this.options = options;\n    _this.listening = false;\n    _this.initialized = false;\n    _this.finished = false;\n    _this.authenticator = options.authenticator;\n    return _this;\n  }\n\n  RecognizeStream.getContentType = function (buffer) {\n    // the substr really shouldn't be necessary, but there's a bug somewhere that can cause buffer.slice(0,4) to return\n    // the entire contents of the buffer, so it's a failsafe to catch that\n    return ibm_cloud_sdk_core_1.contentType.fromHeader(buffer);\n  };\n\n  RecognizeStream.prototype.initialize = function () {\n    var options = this.options; // compatibility\n\n    if (options['X-WDC-PL-OPT-OUT'] && !options['X-Watson-Learning-Opt-Out']) {\n      options['X-Watson-Learning-Opt-Out'] = options['X-WDC-PL-OPT-OUT'];\n    } // process query params\n\n\n    var queryParamsAllowed = ['access_token', 'watson-token', 'model', 'language_customization_id', 'acoustic_customization_id', 'base_model_version', 'x-watson-learning-opt-out', 'x-watson-metadata'];\n    var queryParams = websocket_utils_1.processUserParameters(options, queryParamsAllowed);\n\n    if (!queryParams.language_customization_id && !queryParams.model) {\n      queryParams.model = 'en-US_BroadbandModel';\n    }\n\n    var queryString = ibm_cloud_sdk_core_1.qs.stringify(queryParams); // synthesize the url\n\n    var url = (options.url || 'wss://stream.watsonplatform.net/speech-to-text/api').replace(/^http/, 'ws') + '/v1/recognize?' + queryString; // process opening payload params\n\n    var openingMessageParamsAllowed = ['customization_weight', 'processing_metrics', 'processing_metrics_interval', 'audio_metrics', 'inactivity_timeout', 'timestamps', 'word_confidence', 'content-type', 'interim_results', 'keywords', 'keywords_threshold', 'max_alternatives', 'word_alternatives_threshold', 'profanity_filter', 'smart_formatting', 'speaker_labels', 'grammar_name', 'redaction'];\n    var openingMessage = websocket_utils_1.processUserParameters(options, openingMessageParamsAllowed);\n    openingMessage.action = 'start';\n    var self = this; // node params: requestUrl, protocols, origin, headers, extraRequestOptions, clientConfig options\n    // browser params: requestUrl, protocols (all others ignored)\n    // for the last argument, `tlsOptions` gets passed to Node's `http` library,\n    // which allows us to pass a rejectUnauthorized option\n    // for disabling SSL verification (for ICP)\n    // add custom agent in the request options if given by user\n    // default request options to null\n\n    var agent = options.agent;\n    var requestOptions = agent ? {\n      agent: agent\n    } : null;\n    var socket = this.socket = new websocket_1.w3cwebsocket(url, null, null, options.headers, requestOptions, {\n      tlsOptions: {\n        rejectUnauthorized: !options.disableSslVerification\n      }\n    }); // when the input stops, let the service know that we're done\n\n    self.on('finish', self.finish.bind(self));\n    /**\n     * This can happen if the credentials are invalid - in that case, the response from DataPower doesn't include the\n     * necessary CORS headers, so JS can't even read it :(\n     *\n     * @param {Event} event - event object with essentially no useful information\n     */\n\n    socket.onerror = function (event) {\n      self.listening = false;\n      var err = new Error('WebSocket connection error');\n      err.name = RecognizeStream.WEBSOCKET_CONNECTION_ERROR;\n      err['event'] = event;\n      self.emit('error', err);\n      self.push(null);\n    };\n\n    this.socket.onopen = function () {\n      self.sendJSON(openingMessage);\n      /**\n       * emitted once the WebSocket connection has been established\n       * @event RecognizeStream#open\n       */\n\n      self.emit('open');\n    };\n\n    this.socket.onclose = function (e) {\n      self.listening = false;\n      self.push(null);\n      /**\n       * @event RecognizeStream#close\n       * @param {Number} reasonCode\n       * @param {String} description\n       */\n\n      self.emit('close', e.code, e.reason);\n    };\n    /**\n     * @event RecognizeStream#error\n     * @param {String} msg custom error message\n     * @param {*} [frame] unprocessed frame (should have a .data property with either string or binary data)\n     * @param {Error} [err]\n     */\n\n\n    function emitError(msg, frame, err) {\n      if (err) {\n        err.message = msg + ' ' + err.message;\n      } else {\n        err = new Error(msg);\n      }\n\n      err.raw = frame;\n      self.emit('error', err);\n    }\n\n    socket.onmessage = function (frame) {\n      if (typeof frame.data !== 'string') {\n        return emitError('Unexpected binary data received from server', frame);\n      }\n\n      var data;\n\n      try {\n        data = JSON.parse(frame.data);\n      } catch (jsonEx) {\n        return emitError('Invalid JSON received from service:', frame, jsonEx);\n      }\n      /**\n       * Emit any messages received over the wire, mainly used for debugging.\n       *\n       * @event RecognizeStream#message\n       * @param {Object} message - frame object with a data attribute that's either a string or a Buffer/TypedArray\n       * @param {Object} [data] - parsed JSON object (if possible);\n       */\n\n\n      self.emit('message', frame, data);\n\n      if (data.error) {\n        emitError(data.error, frame);\n      } else if (data.state === 'listening') {\n        // this is emitted both when the server is ready for audio, and after we send the close message to indicate that it's done processing\n        if (self.listening) {\n          self.listening = false;\n          socket.close();\n        } else {\n          self.listening = true;\n          /**\n           * Emitted when the Watson Service indicates readiness to transcribe audio. Any audio sent before this point will be buffered until now.\n           * @event RecognizeStream#listening\n           */\n\n          self.emit('listening');\n        }\n      } else {\n        if (options.readableObjectMode) {\n          /**\n           * Object with interim or final results, possibly including confidence scores, alternatives, and word timing.\n           * @event RecognizeStream#data\n           * @param {Object} data\n           */\n          self.push(data);\n        } else if (Array.isArray(data.results)) {\n          data.results.forEach(function (result) {\n            if (result.final && result.alternatives) {\n              /**\n               * Finalized text\n               * @event RecognizeStream#data\n               * @param {String} transcript\n               */\n              self.push(result.alternatives[0].transcript, 'utf8');\n            }\n          });\n        }\n      }\n    };\n\n    this.initialized = true;\n  };\n\n  RecognizeStream.prototype.sendJSON = function (msg) {\n    /**\n     * Emits any JSON object sent to the service from the client. Mainly used for debugging.\n     * @event RecognizeStream#send-json\n     * @param {Object} msg\n     */\n    this.emit('send-json', msg);\n    return this.socket.send(JSON.stringify(msg));\n  };\n\n  RecognizeStream.prototype.sendData = function (data) {\n    /**\n     * Emits any Binary object sent to the service from the client. Mainly used for debugging.\n     * @event RecognizeStream#send-data\n     * @param {Object} msg\n     */\n    this.emit('send-data', data);\n    return this.socket.send(data);\n  };\n  /**\n   * Flow control - don't ask for more data until we've finished what we have\n   *\n   * Notes:\n   *\n   * This limits upload speed to 100 * options.highWaterMark / second.\n   *\n   * The default highWaterMark is 16kB, so the default max upload speed is ~1.6MB/s.\n   *\n   * Microphone input provides audio at a (downsampled) rate of:\n   *   16000 samples/s * 16-bits * 1 channel = 32kB/s\n   * (note the bits to Bytes conversion there)\n   *\n   * @private\n   * @param {Function} next\n   */\n\n\n  RecognizeStream.prototype.afterSend = function (next) {\n    if (this.socket.bufferedAmount <= (this._writableState.highWaterMark || 0)) {\n      process.nextTick(next);\n    } else {\n      setTimeout(this.afterSend.bind(this, next), 10);\n    }\n  };\n  /**\n   * Prevents any more audio from being sent over the WebSocket and gracefully closes the connection.\n   * Additional data may still be emitted up until the `end` event is triggered.\n   */\n\n\n  RecognizeStream.prototype.stop = function () {\n    /**\n     * Event emitted when the stop method is called. Mainly for synchronising with file reading and playback.\n     * @event RecognizeStream#stop\n     */\n    this.emit('stop');\n    this.finish();\n  };\n\n  RecognizeStream.prototype._read = function () {// there's no easy way to control reads from the underlying library\n    // so, the best we can do here is a no-op\n  };\n\n  RecognizeStream.prototype._write = function (chunk, encoding, callback) {\n    var _this = this;\n\n    this.authenticator.authenticate(this.options).then(function () {\n      var self = _this;\n\n      if (self.finished) {\n        // can't send any more data after the stop message (although this shouldn't happen normally...)\n        return;\n      }\n\n      if (!_this.initialized) {\n        if (!_this.options.contentType) {\n          var ct = RecognizeStream.getContentType(chunk);\n\n          if (ct) {\n            _this.options.contentType = ct;\n          } else {\n            var error = new Error('Unable to determine content-type from file header, please specify manually.');\n            error.name = RecognizeStream.ERROR_UNRECOGNIZED_FORMAT;\n\n            _this.emit('error', error);\n\n            _this.push(null);\n\n            return;\n          }\n        }\n\n        _this.initialize();\n\n        _this.once('open', function () {\n          self.sendData(chunk);\n          self.afterSend(callback);\n        });\n      } else {\n        self.sendData(chunk);\n\n        _this.afterSend(callback);\n      }\n    }, function (err) {\n      _this.emit('error', err);\n\n      _this.push(null);\n    });\n  };\n\n  RecognizeStream.prototype.finish = function () {\n    // this is called both when the source stream finishes, and when .stop() is fired, but we only want to send the stop message once.\n    if (this.finished) {\n      return;\n    }\n\n    this.finished = true;\n    var self = this;\n    var closingMessage = {\n      action: 'stop'\n    };\n\n    if (self.socket && self.socket.readyState === self.socket.OPEN) {\n      self.sendJSON(closingMessage);\n    } else {\n      this.once('open', function () {\n        self.sendJSON(closingMessage);\n      });\n    }\n  };\n  /**\n   * Returns a Promise that resolves with Watson Transaction ID from the X-Transaction-ID header\n   *\n   * Works in Node.js but not in browsers (the W3C WebSocket API does not expose headers)\n   *\n   * @return Promise<String>\n   */\n\n\n  RecognizeStream.prototype.getTransactionId = function () {\n    var _this = this;\n\n    return new Promise(function (resolve, reject) {\n      if (_this.socket && _this.socket._client && _this.socket._client.response && _this.socket._client.response.headers) {\n        resolve(_this.socket._client.response.headers['x-global-transaction-id']);\n      } else {\n        _this.on('open', function () {\n          return resolve(_this.socket._client.response.headers['x-global-transaction-id']);\n        });\n\n        _this.on('error', reject);\n      }\n    });\n  };\n\n  RecognizeStream.WEBSOCKET_CONNECTION_ERROR = 'WebSocket connection error';\n  RecognizeStream.ERROR_UNRECOGNIZED_FORMAT = 'UNRECOGNIZED_FORMAT';\n  return RecognizeStream;\n}(stream_1.Duplex);\n\nmodule.exports = RecognizeStream;","map":null,"metadata":{},"sourceType":"script"}